{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to <code>cmn_ai</code>","text":"<p>I am a big believer in Boyd's Law, which states that speed of iteration beats quality of iteration. Following this principle, I created <code>cmn_ai</code> to incorporate the most common tasks we encounter in ML/AI from data exploration to model development and training. Additionally, I baked into it some of the best practices I learned in my career so I don't have to repeat myself on every project I work on.</p> <p>It is worth noting that the majority of the DL code such as <code>Learner</code> and callbacks assume that <code>pytorch</code> is used as the underlying DL library. Also, tabular data preprocessors/models are compatible with <code>sklearn</code> so they can be used easily with its <code>Pipeline</code> or <code>ColumnTransformer</code>.</p> <p>Given the nature of the progress in ML/AI, I will always keep adding more functionalities as time passes.</p>"},{"location":"learner/","title":"Learner","text":"<p><code>Learner</code> is a basic class that provides useful functionalities:</p> <ul> <li>Tweaking/customization of the training loop using a system of callbacks through Exceptions</li> <li>Loading/saving model</li> <li>Fit the model</li> <li>Get model summary</li> <li>Learning rate finder</li> </ul> <p>The training loop consists of a minimal set of instructions; looping through the data we:</p> <ul> <li>Compute the output of the model from the input</li> <li>Calculate a loss between this output and the desired target</li> <li>Compute the gradients of this loss with respect to model parameters</li> <li>Update the parameters accordingly</li> <li>Zero all the gradients</li> </ul> <p>Any tweak of this training loop is defined in a Callback. A callback can implement actions on the following events:</p> <ul> <li><code>before_fit</code>: called before doing anything, ideal for initial setup</li> <li><code>before_epoch</code>: called at the beginning of each epoch, useful for any behavior you need to reset at each epoch</li> <li><code>before_train</code>: called at the beginning of the training part of an epoch</li> <li><code>before_batch</code>: called at the beginning of each batch, just after drawing said batch. It can be used to do any setup necessary for the batch (like hyper-parameter scheduling) or to change the input/target before it goes in the model (change of the input with techniques like mixup for instance)</li> <li><code>after_pred</code>: called after computing the output of the model on the batch. It can be used to change that output before it's fed to the loss function</li> <li><code>after_loss</code>: called after the loss has been computed, but before the backward pass. It can be used to add any penalty to the loss (AR or TAR in RNN training for instance)</li> <li><code>after_cancel_backward</code>: reached immediately after   CancelBackwardException</li> <li><code>after_backward</code>: called after the backward pass, but before updating the parameters. It can be used to do any change to the gradients before any updates (gradient clipping for instance)</li> <li><code>after_cancel_step</code>: reached immediately after   CancelStepException</li> <li><code>after_step</code>: called after the step and before gradients are zeroed</li> <li><code>after_cancel_batch</code>: reached immediately after   CancelBatchException before proceeding to <code>after_batch</code></li> <li><code>after_batch</code>: called at the end of a batch, for any clean-up before the next one</li> <li><code>after_cancel_train</code>: reached immediately after   CancelTrainException before proceeding to <code>after_train</code></li> <li><code>after_train</code>: called at the end of the training phase of an epoch</li> <li><code>before_validate</code>: called at the beginning of the validation phase of an epoch, useful for any setup needed specifically for validation</li> <li><code>after_cancel_validate</code>: reached immediately after CancelValidateException before proceeding to <code>after_validate</code></li> <li><code>after_validate</code>: called at the end of the validation phase of an epoch</li> <li><code>after_cancel_epoch</code>: reached immediately after   CancelEpochException before proceeding to <code>after_epoch</code></li> <li><code>after_epoch</code>: called at the end of an epoch, for any clean-up before the next one</li> <li><code>after_cancel_fit</code>: reached immediately after   CancelFitException before proceeding to <code>after_fit</code></li> <li><code>after_fit</code>: called at the end of training, for any final clean-up</li> </ul>"},{"location":"learner/#cmn_ai.learner.Learner","title":"<code>Learner</code>","text":"<p>Learner is a basic class that handles training loop of pytorch model and utilize a systems of callbacks that makes training loop very customizable and extensible. You just need to provide a list of callbacks and callback functions.</p> <p>Attributes:</p> Name Type Description <code>model</code> <code>Module</code> <p>Pytorch's model.</p> <code>dls</code> <code>DataLoaders</code> <p>Train and valid data loaders.</p> <code>n_inp</code> <code>int</code> <p>Number of inputs to the model.</p> <code>loss_func</code> <code>Callable[[tensor, tensor], tensor]</code> <p>Loss function.</p> <code>opt_func</code> <code>Optimizer</code> <p>Optimizer function/class.</p> <code>lr</code> <code>float</code> <p>Learning rate.</p> <code>splitter</code> <code>Callable[[Module], Iterable[Parameter]]</code> <p>Function to split model's parameters into groups.</p> <code>path</code> <code>Path</code> <p>Path to save all artifacts.</p> <code>model_dir_path</code> <code>Path</code> <p>Model directory path.</p> <code>callbacks</code> <code>Iterable[Callable] | None, default=None</code> <p>Iterable of callbacks of type <code>Callback</code>.</p> <code>logger</code> <code>Any</code> <p>Logger to log metrics. Default is <code>print</code> but is typically modified by callbacks such as <code>ProgressCallback</code>.</p> <code>callbacks</code> <code>list[Callback]</code> <p>List of all the used callbacks by <code>learner</code>.         <code>TrainEvalCallback</code> is added by <code>learner</code>, so no need to add it.</p>"},{"location":"learner/#cmn_ai.learner.Learner.__init__","title":"<code>__init__(model, dls, n_inp=1, loss_func=F.mse_loss, opt_func=opt.SGD, lr=0.01, splitter=params_getter, path='.', model_dir='models', callbacks=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>Pytorch's model.</p> required <code>dls</code> <code>DataLoaders</code> <p>Train and valid data loaders.</p> required <code>n_inp</code> <code>int</code> <p>Number of inputs to the model.</p> <code>1</code> <code>loss_func</code> <code>Callable[[tensor, tensor], tensor]</code> <p>Loss function.</p> <code>F.mse_loss</code> <code>opt_func</code> <code>Optimizer</code> <p>Optimizer function/class.</p> <code>opt.SGD</code> <code>lr</code> <code>float</code> <p>Learning rate.</p> <code>`1e-2`</code> <code>splitter</code> <code>Callable[[Module], Iterable[Parameter]]</code> <p>Function to split model's parameters into groups, default all parameters belong to 1 group.</p> <code>`params_getter`</code> <code>path</code> <code>str</code> <p>Path to save all artifacts.</p> <code>\".\"</code> <code>model_dir</code> <code>str</code> <p>Model directory name relative to <code>path</code>.</p> <code>\"models\"</code> <code>callbacks</code> <code>Iterable[Callable] | None</code> <p>Iterable of callbacks of type <code>Callback</code>.</p> <code>None</code>"},{"location":"learner/#cmn_ai.learner.Learner.fit","title":"<code>fit(n_epochs=1, run_train=True, run_valid=True, callbacks=None, lr=None, reset_opt=False)</code>","text":"<p>Fit the model for <code>n_epochs</code>.</p> <p>Parameters:</p> Name Type Description Default <code>n_epochs</code> <code>int</code> <p>Number epochs to train the model.</p> <code>1</code> <code>run_train</code> <code>bool</code> <p>Whether to run training passes.</p> <code>True</code> <code>run_valid</code> <code>bool</code> <p>Whether to run validation passes.</p> <code>True</code> <code>callbacks</code> <code>Iterable[Callback] | None</code> <p>Callbacks to add to the existing callbacks. The added callbacks will be removed  before <code>fit</code> returns.</p> <code>None</code> <code>lr</code> <code>float | None</code> <p>Learning rate. If None, <code>lr</code> passed to <code>Learner</code> will be used.</p> <code>None</code> <code>reset_opt</code> <code>bool</code> <p>Whether to reset the optimizer.</p> <code>False</code>"},{"location":"learner/#cmn_ai.learner.Learner.load_model","title":"<code>load_model(path=None, with_opt=False, with_epoch=False, with_loss=False)</code>","text":"<p>Load the model and optionally the optimizer, epoch, and the loss.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path | None</code> <p>Model's file path. If None, use <code>learner.model_dir_path</code>/model.</p> <code>None</code> <code>with_opt</code> <code>bool</code> <p>Whether to load the optimizer state.</p> <code>False</code> <code>with_epoch</code> <code>bool</code> <p>Whether to load the current epoch number.</p> <code>False</code> <code>with_loss</code> <code>bool</code> <p>Whether to load the current loss.</p> <code>False</code>"},{"location":"learner/#cmn_ai.learner.Learner.lr_find","title":"<code>lr_find(start_lr=1e-07, gamma=1.3, num_iter=100, stop_div=True, max_mult=4)</code>","text":"<p>Try different learning rates using exponential schedule to help pick the best learning rate following Cyclical Learning Rates for Training Neural Networks. When done, plot learning rate vs loss.</p> <p>Parameters:</p> Name Type Description Default <code>start_lr</code> <code>float</code> <p>Start learning rate.</p> <code>1e-7</code> <code>gamma</code> <code>float</code> <p>Multiplicative factor of learning rate decay.</p> <code>1.3</code> <code>num_iter</code> <code>int</code> <p>Number of iterations to run the training.</p> <code>100</code> <code>stop_div</code> <code>(bool, default)</code> <p>Whether to stop training if the loss diverges.</p> <code>True</code> <code>max_mult</code> <code>int</code> <p>Divergence threshold. If loss &gt;= max_mult * minimum loss, stop training.</p> <code>4</code>"},{"location":"learner/#cmn_ai.learner.Learner.save_model","title":"<code>save_model(path=None, with_opt=False, with_epoch=False, with_loss=False, pickle_protocol=pickle.HIGHEST_PROTOCOL)</code>","text":"<p>Save the model and optionally the optimizer, epoch, and the loss. Useful for checkpointing.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path | None</code> <p>File path to save the model. If None, use <code>learner.model_dir_path</code>/model.</p> <code>None</code> <code>with_opt</code> <code>bool</code> <p>Whether to save the optimizer state.</p> <code>False</code> <code>with_epoch</code> <code>bool</code> <p>Whether to save the current epoch number.</p> <code>False</code> <code>with_loss</code> <code>bool</code> <p>Whether to save the current loss.</p> <code>False</code> <code>pickle_protocol</code> <code>int</code> <p>Protocol used by pickler when saving the checkpoint.</p> <code>pickle.HIGHEST_PROTOCOL</code>"},{"location":"learner/#cmn_ai.learner.Learner.show_batch","title":"<code>show_batch(sample_sz=1, callbacks=None, **kwargs)</code>","text":"<p>Show <code>sample_sz</code> batch of input. The input would be what the model would see when making predictions. Therefore, all transformations and other augmentation will be applied to the input.</p> <p>Parameters:</p> Name Type Description Default <code>sample_sz</code> <code>int</code> <p>Number of input samples to show.</p> <code>1</code> <code>callbacks</code> <code>Iterable[Callback] | None</code> <p>Callbacks to add to the existing callbacks. The added callbacks will be removed  before <code>show_batch</code> returns.</p> <code>None</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Different types of <code>Learner</code>'s must implement their own version depending on the type of input data. For example, <code>VisionLearner</code>'s would show images.</p>"},{"location":"learner/#cmn_ai.learner.Learner.summary","title":"<code>summary(verbose=2, **kwargs)</code>","text":"<p>Use <code>torchinfo</code> package to print out the model summary.</p>"},{"location":"learner/#cmn_ai.learner.params_getter","title":"<code>params_getter(model)</code>","text":"<p>Get all parameters of <code>model</code> recursively.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>Model.</p> required <p>Yields:</p> Type Description <code>Parameter</code> <p>Module parameter.</p>"},{"location":"losses/","title":"Losses","text":""},{"location":"losses/#cmn_ai.losses.LabelSmoothingCrossEntropy","title":"<code>LabelSmoothingCrossEntropy</code>","text":"<p>               Bases: <code>Module</code></p> <p>Label smoothing is designed to make the model a little bit less certain of it's decision by changing a little bit its target: instead of wanting to predict 1 for the correct class and 0 for all the others, we ask it to predict <code>1 - \u03b5</code> for the correct class and <code>\u03b5</code> for all the others, with <code>\u03b5</code> a (small) positive number.</p>"},{"location":"losses/#cmn_ai.losses.LabelSmoothingCrossEntropy.__init__","title":"<code>__init__(eps=0.1, reduction='mean')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>eps</code> <code>float</code> <p>Weight for the interpolation formula.</p> <code>0.1</code> <code>reduction</code> <code>str</code> <p>Reduction applied to the loss tensor.</p> <code>mean</code>"},{"location":"losses/#cmn_ai.losses.NoneReduce","title":"<code>NoneReduce</code>","text":"<p>Force non-reduction on the loss tensor so it can used later in methods such as <code>Mixup</code> or <code>LabelSmoothing</code>.</p>"},{"location":"losses/#cmn_ai.losses.NoneReduce.__init__","title":"<code>__init__(loss_func)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>loss_func</code> <code>Callable</code> <p>Loss function.</p> required"},{"location":"losses/#cmn_ai.losses.reduce_loss","title":"<code>reduce_loss(loss, reduction=None)</code>","text":"<p>Reduce the <code>loss</code> tensor using <code>reduction</code> method. If <code>reduction</code> is None, returns the passed loss tensor.</p> <p>Parameters:</p> Name Type Description Default <code>loss</code> <code>Tensor</code> <p>Loss tensor.</p> required <code>reduction</code> <code>str | None</code> <p>Reduction applied to the loss tensor.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Reduced loss tensor.</p>"},{"location":"plot/","title":"Plotting","text":"<p>This module provides different plotting utilities that are commonly used in ML context such as plotting a grid of images or show a single image.</p>"},{"location":"plot/#cmn_ai.plot.get_grid","title":"<code>get_grid(n, nrows=None, ncols=None, title=None, weight='bold', size=14, **kwargs)</code>","text":"<p>Return a grid of <code>n</code> axes, <code>rows</code> by <code>cols</code>. <code>nrows</code> and <code>ncols</code> are mutually exclusive. This means you only need to pass one of them and the other will be inferred.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of axes.</p> required <code>nrows</code> <code>int</code> <p>Number of rows, default=<code>int(math.sqrt(n))</code>.</p> <code>None</code> <code>ncols</code> <code>int</code> <p>Number of columns, default=<code>ceil(n/rows)</code>.</p> <code>None</code> <code>title</code> <code>str</code> <p>Title of the Figure.</p> <code>None</code> <code>weight</code> <code>str</code> <p>Title font weight.</p> <code>'bold'</code> <code>size</code> <code>int</code> <p>Title font size.</p> <code>14</code> <p>Returns:</p> Name Type Description <code>fig</code> <code>Figure</code> <p>Top level container for all axes.</p> <code>ax</code> <code>array of Axes</code> <p>Array of axes.</p>"},{"location":"plot/#cmn_ai.plot.show_image","title":"<code>show_image(image, ax=None, figsize=None, title=None, noframe=True, **kwargs)</code>","text":"<p>Show a PIL or PyTorch image on <code>ax</code>.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>PIL image or array-like</code> <p>Image data.</p> required <code>ax</code> <code>Axes</code> <p>Axes to plot the image on.</p> <code>None</code> <code>figsize</code> <code>tuple</code> <p>Width, height in inches of the returned Figure</p> <code>None</code> <code>title</code> <code>str</code> <p>Title of the image</p> <code>None</code> <code>noframe</code> <code>bool</code> <p>Whether to remove axis from the plotted image.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>ax</code> <code>AxesImage</code> <p>Plotted image on <code>ax</code>.</p>"},{"location":"plot/#cmn_ai.plot.show_images","title":"<code>show_images(images, nrows=None, ncols=None, titles=None, **kwargs)</code>","text":"<p>Show all images as subplots with <code>nrows</code> x <code>ncols</code> using <code>titles</code>.</p> <p>Parameters:</p> Name Type Description Default <code>images</code> <code>list or array - like</code> <p>List of images to show.</p> required <code>nrows</code> <code>int</code> <p>Number of rows in the grid.</p> <code>None</code> <code>ncols</code> <code>int</code> <p>Number of columns in the grid.</p> <code>None</code> <code>titles</code> <code>list</code> <p>List of titles for each image.</p> <code>None</code>"},{"location":"plot/#cmn_ai.plot.subplots","title":"<code>subplots(nrows=1, ncols=1, figsize=None, imsize=3, suptitle=None, **kwargs)</code>","text":"<p>A figure and set of subplots to display images of <code>imsize</code> inches.</p> <p>Parameters:</p> Name Type Description Default <code>nrows</code> <code>int</code> <p>Number of rows in returned axes grid.</p> <code>1</code> <code>ncols</code> <code>int</code> <p>Number of columns in returned axes grid.</p> <code>1</code> <code>figsize</code> <code>tuple</code> <p>Width, height in inches of the returned Figure.</p> <code>None</code> <code>imsize</code> <code>int</code> <p>Size (in inches) of images that will be displayed in the returned figure.</p> <code>3</code> <code>suptitle</code> <code>str</code> <p>Title of the Figure.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>fig</code> <code>Figure</code> <p>Top level container for all axes.</p> <code>ax</code> <code>array of Axes</code> <p>Array of axes.</p>"},{"location":"callbacks/core/","title":"Core","text":"<p>The main module that has the definition of the <code>Callback</code> base class as well as all the Exceptions that a callback may raise.</p>"},{"location":"callbacks/core/#cmn_ai.callbacks.core.Callback","title":"<code>Callback</code>","text":"<p>Base class for all callbacks.</p>"},{"location":"callbacks/core/#cmn_ai.callbacks.core.Callback.name","title":"<code>name: str</code>  <code>property</code>","text":"<p>Returns the name of the callback after removing the word <code>callback</code> and then convert it to snake (split words by underscores).</p>"},{"location":"callbacks/core/#cmn_ai.callbacks.core.Callback.__getattr__","title":"<code>__getattr__(k)</code>","text":"<p>This would allow us to use <code>self.obj</code> instead of <code>self.learner.obj</code> when we know <code>obj</code> is in learner because it will only be called when <code>getattribute</code> returns <code>AttributeError</code>.</p>"},{"location":"callbacks/core/#cmn_ai.callbacks.core.Callback.camel2snake","title":"<code>camel2snake(name)</code>  <code>staticmethod</code>","text":"<p>Convert name of callback by inserting underscores between small and capital letters. For example, <code>TestCallback</code> becomes <code>test_callback</code>.</p>"},{"location":"callbacks/core/#cmn_ai.callbacks.core.Callback.set_learner","title":"<code>set_learner(learner)</code>","text":"<p>Set the learner as an attribute so that callbacks can access learner's attributes without the need to pass <code>learner</code> for every single method in every callback.</p> <p>Parameters:</p> Name Type Description Default <code>learner</code> <code>Learner</code> <p>Learner that the callback will be called when some events happens.</p> required"},{"location":"callbacks/core/#cmn_ai.callbacks.core.CancelBackwardException","title":"<code>CancelBackwardException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Skip the backward pass and move to <code>after_backward</code>.</p>"},{"location":"callbacks/core/#cmn_ai.callbacks.core.CancelBatchException","title":"<code>CancelBatchException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Stop current batch and move to <code>after_batch</code>.</p>"},{"location":"callbacks/core/#cmn_ai.callbacks.core.CancelEpochException","title":"<code>CancelEpochException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Stop current epoch and move to <code>after_epoch</code>.</p>"},{"location":"callbacks/core/#cmn_ai.callbacks.core.CancelFitException","title":"<code>CancelFitException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Stop training and move to <code>after_fit</code>.</p>"},{"location":"callbacks/core/#cmn_ai.callbacks.core.CancelStepException","title":"<code>CancelStepException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Skip stepping the optimizer and move to <code>after_step</code>.</p>"},{"location":"callbacks/core/#cmn_ai.callbacks.core.CancelTrainException","title":"<code>CancelTrainException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Stop training current epoch and move to <code>after_train</code>.</p>"},{"location":"callbacks/core/#cmn_ai.callbacks.core.CancelValidateException","title":"<code>CancelValidateException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Stop validation phase and move to <code>after_validate</code>.</p>"},{"location":"callbacks/hook/","title":"Hooks","text":"<p>Hooks are very useful to inspect what is happening during the forward and backward passes such as computing stats of the activations and gradients.</p> <p>The module contains the following classes:</p> <ul> <li><code>Hook</code>: Registers forward or backward hook for a single module</li> <li><code>Hooks</code>: Registers forward or backward hook for multiple modules</li> <li><code>HooksCallback</code>: Use callbacks to register and manage hooks</li> <li><code>ActivationStats</code>: Computes means/stds for either activation or     gradients and plot the computed stats.</li> </ul>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.ActivationStats","title":"<code>ActivationStats</code>","text":"<p>               Bases: <code>HooksCallback</code></p> <p>Plot the means, std, histogram, and dead activations of all modules' activations if <code>is_forward</code> else gradients.</p>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.ActivationStats.__init__","title":"<code>__init__(modules=None, is_forward=True, bins=40, bins_range=(0, 10))</code>","text":"<p>Parameters:</p> Name Type Description Default <code>modules</code> <code>Module | Iterable[Module] | None</code> <p>Modules to register the hook on. Default to all modules.</p> <code>None</code> <code>is_forward</code> <code>bool</code> <p>Whether to register <code>func</code> as a forward or backward hook.</p> <code>True</code> <code>bins</code> <code>int</code> <p>Number of histogram bins.</p> <code>40</code> <code>bins_range</code> <code>Iterable</code> <p>Lower/Upper end of the histogram's bins range.</p> <code>(0, 10)</code>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.ActivationStats.dead_chart","title":"<code>dead_chart(bins_range, figsize=(11, 5))</code>","text":"<p>Plot a line chart of the \"dead\" activations percentage from all activations.</p> <p>Parameters:</p> Name Type Description Default <code>bins_range</code> <code>list | tuple</code> <p>Bins range around zero. Bins that are considered dead activations/gradients.</p> required <code>figsize</code> <code>tuple</code> <p>Width, height of the figure.</p> <code>(11, 5)</code>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.ActivationStats.plot_hist","title":"<code>plot_hist(figsize=(11, 5))</code>","text":"<p>Plot histogram of activations/gradients as a heatmap.</p> <p>Parameters:</p> Name Type Description Default <code>figsize</code> <code>(tuple, de)</code> <p>Width, height of the heatmap figure.</p> <code>(11, 5)</code>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.ActivationStats.plot_stats","title":"<code>plot_stats(figsize=(10, 4))</code>","text":"<p>Plot means of standard deviation of activations/gradients for each layer that has a registered hook.</p> <p>Parameters:</p> Name Type Description Default <code>figsize</code> <code>tuple</code> <p>Width, height of the figure.</p> <code>(10, 4)</code>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.Hook","title":"<code>Hook</code>","text":"<p>Register either a forward or a backward hook on the module.</p>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.Hook.__init__","title":"<code>__init__(module, func, is_forward=True, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>module</code> <code>Module</code> <p>The module to register the hook on.</p> required <code>func</code> <code>Callable</code> <p>The hook to be registered.</p> required <code>is_forward</code> <code>bool</code> <p>Whether to register <code>func</code> as a forward or backward hook.</p> <code>True</code>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.Hooks","title":"<code>Hooks</code>","text":"<p>Register hooks on all modules.</p>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.Hooks.__init__","title":"<code>__init__(modules, func, is_forward=True, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>modules</code> <code>Iterable[Module]</code> <p>The module to register the hook on.</p> required <code>func</code> <code>Callable</code> <p>The hook to be registered.</p> required <code>is_forward</code> <code>bool</code> <p>Whether to register <code>func</code> as a forward or backward hook.</p> <code>True</code>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.HooksCallback","title":"<code>HooksCallback</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Base class to run hooks on modules as a callback.</p>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.HooksCallback.__init__","title":"<code>__init__(hookfunc, on_train=True, on_valid=False, modules=None, is_forward=True)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>hookfunc</code> <code>Callable</code> <p>The hook to be registered.</p> required <code>on_train</code> <code>bool</code> <p>Whether to run the hook on modules during training.</p> <code>True</code> <code>on_valid</code> <code>bool</code> <p>Whether to run the hook on modules during validation.</p> <code>False</code> <code>modules</code> <code>Module | Iterable[Module] | None</code> <p>Modules to register the hook on. Default to all modules.</p> <code>None</code> <code>is_forward</code> <code>bool</code> <p>Whether to register <code>func</code> as a forward or backward hook.</p> <code>True</code>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.compute_stats","title":"<code>compute_stats(hook, module, inp, outp, bins=40, bins_range=(0, 10))</code>","text":"<p>Compute the means, std, and histogram of <code>module</code> activations/gradients and the <code>hook</code> stats.</p> <p>Parameters:</p> Name Type Description Default <code>hook</code> <code>Hook</code> <p>Registered hook on the provided module.</p> required <code>module</code> <code>Module</code> <p>Module to compute the stats on.</p> required <code>inp</code> <code>Tensor</code> <p>Input of the module.</p> required <code>outp</code> <code>Tensor</code> <p>Output of the module.</p> required <code>bins</code> <code>int</code> <p>Number of histogram bins.</p> <code>40</code> <code>bins_range</code> <code>Iterable</code> <p>lower/upper end of the histogram's bins range.</p> <code>(0, 10)</code>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.get_hist","title":"<code>get_hist(hook)</code>","text":"<p>Return matrix-ready for plotting heatmap of activations/gradients.</p>"},{"location":"callbacks/hook/#cmn_ai.callbacks.hook.get_min","title":"<code>get_min(hook, bins_range)</code>","text":"<p>Compute the percentage of activations/gradients around zero from hook's histogram matrix.</p> <p>Parameters:</p> Name Type Description Default <code>hook</code> <code>Hook</code> <p>Hook that has the stats of the activations</p> required <code>bins_range</code> <code>list | tuple</code> <p>Bins range around zero.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Percentage of the activations around zero.</p>"},{"location":"callbacks/schedule/","title":"Schedule","text":"<p>This module provides commonly used schedulers with hyperparameters such as learning rate.</p> <p>It is very important to remember to apply hyperparameters update such as learning rate update after optimizer's update. This means that it should be either in <code>before_batch</code> OR <code>after_batch</code> in our framework.</p> <p>We have two choices to schedule hyperparameters:</p> <ul> <li>Use any subclass of <code>Scheduler</code> such as BatchScheduler and pass any scheduler from pytorch's schedulers</li> <li>Use ParamScheduler and pass it any callable that takes the position and returns the hyperparameter value such as exp_sched</li> </ul>"},{"location":"callbacks/schedule/#cmn_ai.callbacks.schedule.BatchScheduler","title":"<code>BatchScheduler</code>","text":"<p>               Bases: <code>Scheduler</code></p> <p>Change hyperparameters after every batch using <code>scheduler</code>.</p>"},{"location":"callbacks/schedule/#cmn_ai.callbacks.schedule.EpochScheduler","title":"<code>EpochScheduler</code>","text":"<p>               Bases: <code>Scheduler</code></p> <p>Change hyperparameters after every epoch using <code>scheduler</code>.</p>"},{"location":"callbacks/schedule/#cmn_ai.callbacks.schedule.ParamScheduler","title":"<code>ParamScheduler</code>","text":"<p>               Bases: <code>Callback</code></p> <p>This class is used to schedule the values of hyperparameters during the training process.</p>"},{"location":"callbacks/schedule/#cmn_ai.callbacks.schedule.ParamScheduler.__init__","title":"<code>__init__(pname, sched_funcs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>pname</code> <code>str</code> <p>The name of the hyperparameter to be scheduled.</p> required <code>sched_funcs</code> <code>list[Callabel] | tuple[Callable]</code> <p>A list or tuple of schedulers for each parameter group. Each scheduler should accept a single argument (position) and return a value for the hyperparameter.</p> required"},{"location":"callbacks/schedule/#cmn_ai.callbacks.schedule.Scheduler","title":"<code>Scheduler</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Base scheduler to change hyperparameters using <code>scheduler</code>.</p> <p>Note</p> <p>Pytorch's schedulers take optimizer as the first argument. Therefore, it is important to pass the scheduler that has all its arguments already passed except the optimizer. This will be done in <code>Scheduler</code>'s <code>before_fit</code> method. For example: <pre><code>Scheduler(partial(torch.opt.lr_schedule.OneCycleLR, max_lr=1e-2, total_steps=1000))\n</code></pre></p>"},{"location":"callbacks/schedule/#cmn_ai.callbacks.schedule.combine_scheds","title":"<code>combine_scheds(pcts, scheds)</code>","text":"<p>Combine multiple schedulers, each run for a given percentage of the training process.</p>"},{"location":"callbacks/schedule/#cmn_ai.callbacks.schedule.cos_1cycle_anneal","title":"<code>cos_1cycle_anneal(start, high, end)</code>","text":"<p>combine two cosine schedulers where first scheduler goes from <code>start</code> to <code>high</code> and second scheduler goes from <code>high</code> to <code>end</code>.</p>"},{"location":"callbacks/schedule/#cmn_ai.callbacks.schedule.cos_sched","title":"<code>cos_sched(start, end, pos)</code>","text":"<p>Cosine scheduler.</p>"},{"location":"callbacks/schedule/#cmn_ai.callbacks.schedule.exp_sched","title":"<code>exp_sched(start, end, pos)</code>","text":"<p>Exponential scheduler.</p>"},{"location":"callbacks/schedule/#cmn_ai.callbacks.schedule.lin_sched","title":"<code>lin_sched(start, end, pos)</code>","text":"<p>Linear scheduler.</p>"},{"location":"callbacks/schedule/#cmn_ai.callbacks.schedule.no_sched","title":"<code>no_sched(start, end, pos)</code>","text":"<p>Constant schedular.</p>"},{"location":"callbacks/training/","title":"Training","text":"<p>Almost all training's related callbacks that will tweak/customize the training/validation loop is in this module.</p> <p>Raises:</p> Type Description <code>CancelFitException</code> <p>Stop training and move to after_fit.</p> <code>CancelEpochException</code> <p>Stop current epoch and move to after_epoch.</p> <code>CancelTrainException</code> <p>Stop training current epoch and move to after_train.</p> <code>CancelValidException</code> <p>Stop validation phase and move after_validate.</p> <code>CancelBatchException</code> <p>Stop current batch and move to after_batch.</p> <code>CancelStepException</code> <p>Skip stepping the optimizer.</p> <code>CancelBackwardException</code> <p>Skip the backward pass and move to after_backward.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.BatchTransform","title":"<code>BatchTransform</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Transform batch using <code>tfm</code> callable before every batch. Apply transformation <code>tfm</code> on the batch as a whole.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.BatchTransform.__init__","title":"<code>__init__(tfm, on_train=True, on_valid=True)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>tfm</code> <code>Callback</code> <p>Transformation to apply on the batch.</p> required <code>on_train</code> <code>bool</code> <p>Whether to apply the transformation during training.</p> <code>True</code> <code>on_valid</code> <code>bool</code> <p>Whether to apply the transformation during validation.</p> <code>True</code>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.BatchTransformX","title":"<code>BatchTransformX</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Transform X using <code>tfm</code> callable before every batch. Apply transformation <code>tfm</code> on the batch as a whole.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.BatchTransformX.__init__","title":"<code>__init__(tfm, on_train=True, on_valid=True)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>tfm</code> <code>Callback</code> <p>Transformation to apply on the batch.</p> required <code>on_train</code> <code>bool</code> <p>Whether to apply the transformation during training.</p> <code>True</code> <code>on_valid</code> <code>bool</code> <p>Whether to apply the transformation during validation.</p> <code>True</code>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.DeviceCallback","title":"<code>DeviceCallback</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Move batch and model to <code>device</code>.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.DeviceCallback.__init__","title":"<code>__init__(device=default_device)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>device</code> <code>str | device</code> <p>Device to copy batch to.</p> <code>default_device</code>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.LRFinder","title":"<code>LRFinder</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Try different learning rates using exponential schedule to help pick the best learning rate following Cyclical Learning Rates for Training Neural Networks. When done, plot learning rate vs loss.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.LRFinder.__init__","title":"<code>__init__(gamma=1.3, num_iter=100, stop_div=True, max_mult=4)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>end_lr</code> <code>float</code> <p>Last learning rate in the schedule.</p> <code>10.0</code> <code>num_iter</code> <code>int</code> <p>Number of iterations to run the training.</p> <code>100</code> <code>stop_div</code> <code>(bool, default)</code> <p>Whether to stop training if loss diverges (loss &gt; 4 * best_loss).</p> <code>True</code> <code>max_mult</code> <code>int</code> <p>Divergence threshold. If loss &gt;= max_mult * minimum loss, stop training.</p> <code>4</code>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.MetricsCallback","title":"<code>MetricsCallback</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Compute/update given metrics and log it using <code>learner</code> defined logger after every <code>train</code>/<code>validate</code> epoch. Metrics have to implement <code>reset</code> and <code>compute</code> methods. Highly recommended to use metrics from <code>torcheval</code> package or inherit from its Metrics baseclass for custom metrics.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.Mixup","title":"<code>Mixup</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Train the model with a mix of samples from each batch in the training data. Instead of feeding the model with raw data, we use linear combination of the input using <code>alpha</code> from beta distribution. This means that the labels would also be the linear combination of the labels and not the original labels. The implementation is largely based on this paper.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.Mixup.__init__","title":"<code>__init__(alpha=0.4)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>float</code> <p>Concentration for Beta distribution.</p> <code>0.4</code>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.Mixup.before_batch","title":"<code>before_batch()</code>","text":"<p>Steps taken before passing inputs to the model:</p> <ul> <li>Draw from a beta distribution a sample of size of <code>batch_size</code>.   Each image would have its own <code>\u03bb</code>.</li> <li>To avoid having two images combined together with the same <code>\u03bb</code>,   we take the max of <code>\u03bb</code> and <code>1 - \u03bb</code> so even if they were combined   together they would lead to a different image.</li> <li>Shuffle the batch before computing the linear combination.</li> <li>Change the batch input to be the linear combination of both the   original image and the shuffled images.</li> </ul> <p>The loss would be the linear combination of the loss of the original images with the original target and the shuffled image with the shuffled target weighted by <code>\u03bb</code>.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.ModelResetter","title":"<code>ModelResetter</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Reset model's parameters. This is very useful in the context of NLP since we always reset hidden state. The assumption here is that <code>model</code> has a <code>reset</code> method that knows which parameters to reset and how.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.ProgressCallback","title":"<code>ProgressCallback</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Track progress of training using progress bar as well as to plot losses (train and valid), which allows us to have live feedback of the model's performance while it is still training.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.ProgressCallback.__init__","title":"<code>__init__(plot=True)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>plot</code> <code>bool</code> <p>Whether to plot train/valid losses during training.</p> <code>True</code>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.Recorder","title":"<code>Recorder</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Keep track of losses and <code>params</code> of the optimizer such as learning rates as training progress so we can plot them later.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.Recorder.plot","title":"<code>plot(pgid=-1, skip_last=0)</code>","text":"<p>Plot loss vs lr (log-scale) across all iterations of training.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.Recorder.plot_loss","title":"<code>plot_loss(skip_last=0)</code>","text":"<p>Plot losses, optionally skip last <code>skip_last</code> losses.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.Recorder.plot_params","title":"<code>plot_params(params='lr', pgid=-1, figsize=(8, 6))</code>","text":"<p>Plot all <code>params</code> values across all iterations of training.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.SingleBatchCallback","title":"<code>SingleBatchCallback</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Run 1 training/validation batch and stop by raising <code>CancelFitException</code>. Useful for debugging or want to check few parameters after 1 batch.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.SingleBatchForwardCallback","title":"<code>SingleBatchForwardCallback</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Run 1 training/validation batch and stop after forward pass (after computing loss) by raising <code>CancelFitException</code>. Useful for debugging or want to check few parameters after 1 batch.</p>"},{"location":"callbacks/training/#cmn_ai.callbacks.training.TrainEvalCallback","title":"<code>TrainEvalCallback</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Tracks the number of iterations, percentage of training, and set training and eval modes.</p>"},{"location":"tabular/eda/","title":"EDA","text":"<p>Exploratory Data Analysis (EDA) is the first thing that needs to be done before start working on model development. This module contains common utilities for EDA on tabular data. Most of these functions are around plotting, data quality, and computing stats on the data.</p>"},{"location":"tabular/eda/#cmn_ai.tabular.eda.get_ecdf","title":"<code>get_ecdf(a)</code>","text":"<p>Compute empirical cumulative distribution function of <code>a</code>.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>list, Array, or pd.Series</code> <p>Array to compute ECDF on.</p> required <p>Returns:</p> Name Type Description <code>x</code> <code>array</code> <p>Sorted version of given array in ascending order.</p> <code>y</code> <code>array</code> <p>Cumulative probability of each value if the sorted array.</p>"},{"location":"tabular/eda/#cmn_ai.tabular.eda.na_percentages","title":"<code>na_percentages(df, formatted=True)</code>","text":"<p>Compute percentage of missing values in <code>df</code> columns.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Dataframe to compute missing values.</p> required <code>formatted</code> <code>bool</code> <p>Whether to return styled/formatted dataframe or raw percentages.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>res</code> <code>Series or DataFrame</code> <p>Percentages of missing values in each column.</p>"},{"location":"tabular/eda/#cmn_ai.tabular.eda.plot_corr_matrix","title":"<code>plot_corr_matrix(df, method='pearson', figsize=(12, 6))</code>","text":"<p>Plot <code>method</code> correlation matrix heatmap.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Dataframe to compute correlation.</p> required <code>method</code> <code>str</code> <p>Method of correlation.</p> <code>'pearson'</code> <code>figsize</code> <code>tuple</code> <p>Figure size.</p> <code>(12, 6)</code>"},{"location":"tabular/eda/#cmn_ai.tabular.eda.plot_ecdf","title":"<code>plot_ecdf(a, xlabel='X')</code>","text":"<p>Plot empirical cumulative distribution of <code>a</code>.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>list, Array, or pd.Series</code> <p>Array to compute ECDF on.</p> required <code>xlabel</code> <code>str</code> <p>XlLabel of the plot.</p> <code>\"X\"</code>"},{"location":"tabular/eda/#cmn_ai.tabular.eda.plot_featurebased_hier_clustering","title":"<code>plot_featurebased_hier_clustering(X, feature_names=None, linkage_method='single', figsize=(16, 12))</code>","text":"<p>Plot features-based hierarchical clustering based on spearman correlation matrix.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray | DataFrame</code> <p>Data to compute hierarchical clustering.</p> required <code>feature_names</code> <code>ndarray | list | None</code> <p>Feature names to use as labels with plotting.</p> <code>None</code> <code>linkage_method</code> <code>str</code> <p>method for calculating the distance between clusters.</p> <code>\"single\"</code> <code>figsize</code> <code>tuple</code> <p>Figure size.</p> <code>(16, 12)</code>"},{"location":"tabular/eda/#cmn_ai.tabular.eda.plot_pca_var_explained","title":"<code>plot_pca_var_explained(pca_transformer, figsize=(12, 6))</code>","text":"<p>Plot individual and cumulative of the variance explained by each PCA component.</p> <p>Parameters:</p> Name Type Description Default <code>pca_transformer</code> <code>PCA</code> <p>Fitted PCA transformer.</p> required <code>figsize</code> <code>tuple</code> <p>Figure size.</p> <code>(12, 6)</code>"},{"location":"tabular/preprocessing/","title":"Preprocessing","text":"<p>Most datasets need to be preprocessed/transformed before they can be passed to the model. This module includes common transformers that are compatible with <code>sklearn</code> <code>Pipeline</code> or <code>ColumnTransformer</code>.</p>"},{"location":"tabular/preprocessing/#cmn_ai.tabular.preprocessing.DateTransformer","title":"<code>DateTransformer</code>","text":"<p>               Bases: <code>TransformerMixin</code>, <code>BaseEstimator</code></p> <p>Transform date features by deriving useful date/time attributes:</p> <ul> <li>date attributes: <code>Year, Month, Week, Day, Dayofweek, Dayofyear, Is_month_end, Is_month_start, Is_quarter_end, Is_quarter_start, Is_year_end, Is_year_start</code>.</li> <li>time attributes: <code>Hour, Minute, Second</code>.</li> </ul>"},{"location":"tabular/preprocessing/#cmn_ai.tabular.preprocessing.DateTransformer.__init__","title":"<code>__init__(date_feats=None, time=False, drop=True)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>date_feats</code> <code>Iterable</code> <p>Date features to transform. If None, all features with <code>datetime64</code> data type will be used.</p> <code>None</code> <code>time</code> <code>bool</code> <p>Whether to add time-related derived features such as Hour/Minute/...</p> <code>False</code> <code>drop</code> <code>bool</code> <p>Whether to drop date features used.</p> <code>True</code>"},{"location":"tabular/preprocessing/#cmn_ai.tabular.preprocessing.DateTransformer.fit","title":"<code>fit(X, y=None)</code>","text":"<p>Populate date features if not provided at initialization.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>DataFrame</code> <p>Dataframe that has the date features to transform.</p> required <code>y</code> <code>array | DataFrame | None</code> <p>Included for completeness to be compatible with scikit-learn transformers and pipelines but will not be used.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>self</code> <code>DateTransformer</code> <p>Fitted date transformer.</p>"},{"location":"tabular/preprocessing/#cmn_ai.tabular.preprocessing.DateTransformer.transform","title":"<code>transform(X, y=None)</code>","text":"<p>Derive the date/time attributes for all date features.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>DataFrame</code> <p>Dataframe that has the date features to transform.</p> required <code>y</code> <code>array | DataFrame | None</code> <p>Included for completeness to be compatible with scikit-learn transformers and pipelines but will not be used.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>X_tr</code> <code>DataFrame</code> <p>Dataframe with derived date/time features and NaN indicators.</p>"},{"location":"text/data/","title":"Data","text":""},{"location":"text/data/#cmn_ai.text.data.TextList","title":"<code>TextList</code>","text":"<p>               Bases: <code>ItemList</code></p> <p>Build a text list from list of files in the <code>path</code> end with <code>extensions</code>, optionally recursively.</p>"},{"location":"text/data/#cmn_ai.text.data.TextList.from_files","title":"<code>from_files(path, extensions='.txt', include=None, recurse=True, tfms=None, encoding='utf8')</code>  <code>classmethod</code>","text":"<p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path for the root directory to search for files.</p> required <code>extensions</code> <code>str | Iterable[str] | None</code> <p>Suffixes of filenames to look for.</p> <code>IMAGE_EXTENSIONS</code> <code>include</code> <code>Iterable[str] | None</code> <p>Top-level Director(y|ies) under <code>path</code> to use to search for files.</p> <code>None</code> <code>recurse</code> <code>bool</code> <p>Whether to search subdirectories recursively.</p> <code>True</code> <code>tfms</code> <code>Callable | None</code> <p>Transformations to apply items before returning them.</p> <code>None</code> <code>encoding</code> <code>str</code> <p>Name of encoding used to decode files.</p> <code>utf8</code>"},{"location":"text/data/#cmn_ai.text.data.TextList.get","title":"<code>get(i)</code>","text":"<p>Returns text in the file as string if <code>i</code> is path to a file.</p>"},{"location":"utils/data/","title":"Data","text":"<p>This module includes most of the utilities related to working with data in general, and with <code>pytorch</code>'s related data in specific. It includes functions from composing transforms and getting train/valid <code>DataLoader</code>s to splitting and labeling <code>Dataset</code>s.</p>"},{"location":"utils/data/#cmn_ai.utils.data.DataLoaders","title":"<code>DataLoaders</code>","text":"<p>Create train/valid DataLoaders.</p>"},{"location":"utils/data/#cmn_ai.utils.data.DataLoaders.__init__","title":"<code>__init__(*dls)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>dls</code> <p>list of DataLoaders.</p> <code>()</code>"},{"location":"utils/data/#cmn_ai.utils.data.DataLoaders.from_dd","title":"<code>from_dd(dd, batch_size, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create train/valid data loaders from HF Dataset dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>dd</code> <code>DatasetDict</code> <p>HF Dataset dictionary. Must have at least two datasets: train and valid/test datasets.</p> required <code>batch_size</code> <code>int</code> <p>batch size passed to DataLoader.</p> required <p>Returns:</p> Type Description <code>tuple[DataLoader]</code> <p>Train/valid data loaders.</p>"},{"location":"utils/data/#cmn_ai.utils.data.ItemList","title":"<code>ItemList</code>","text":"<p>               Bases: <code>ListContainer</code></p> <p>Base class for all types of datasets such as image, text, etc.</p>"},{"location":"utils/data/#cmn_ai.utils.data.ItemList.__init__","title":"<code>__init__(items, path='.', tfms=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>items</code> <code>Sequence</code> <p>Items to create list.</p> required <code>path</code> <code>str | Path</code> <p>Path of the items that were used to create the list.</p> <code>\".\"</code> <code>tfms</code> <code>Callable | None</code> <p>Transformations to apply on items before returning them.</p> <code>None</code>"},{"location":"utils/data/#cmn_ai.utils.data.ItemList.get","title":"<code>get(item)</code>","text":"<p>Every class that inherits from <code>ItemList</code> has to override this method.</p>"},{"location":"utils/data/#cmn_ai.utils.data.ItemList.new","title":"<code>new(items, cls=None)</code>","text":"<p>Create a new instance of the <code>ItemList</code> with <code>items</code>.</p> <p>Parameters:</p> Name Type Description Default <code>items</code> <code>Sequence</code> <p>The items to create the list from.</p> required <code>cls</code> <code>ItemList | None</code> <p>The class to instantiate. If None, the same class will be used.</p> <code>None</code> <p>Returns:</p> Type Description <code>ItemList</code> <p>The new instance of the <code>ItemList</code>.</p>"},{"location":"utils/data/#cmn_ai.utils.data.LabeledData","title":"<code>LabeledData</code>","text":"<p>Create a labeled data and expose both x &amp; y as item lists after passing them through all processors.</p>"},{"location":"utils/data/#cmn_ai.utils.data.LabeledData.__init__","title":"<code>__init__(x, y, proc_x=None, proc_y=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>x</code> <code>ItemList</code> <p>Input items to the model.</p> required <code>y</code> <code>ItemList</code> <p>Label items.</p> required <code>proc_x</code> <code>Processor | Iterable[Processor] | None</code> <p>Input items processor(s).</p> <code>None</code> <code>proc_y</code> <code>Processor | Iterable[Processor] | None</code> <p>Label items processor(s).</p> <code>None</code>"},{"location":"utils/data/#cmn_ai.utils.data.LabeledData.label_by_func","title":"<code>label_by_func(item_list, label_func, proc_x=None, proc_y=None)</code>  <code>classmethod</code>","text":"<p>Label an ItemList using a labeling function.</p> <p>Parameters:</p> Name Type Description Default <code>item_list</code> <code>ItemList</code> <p>The ItemList to be labeled.</p> required <code>label_func</code> <code>Callable</code> <p>The function to be used for labeling.</p> required <code>proc_x</code> <code>Callable | None</code> <p>The processor to be applied to the input data.</p> <code>None</code> <code>proc_y</code> <code>Callable | None</code> <p>The processor to be applied to the label data.</p> <code>None</code> <p>Returns:</p> Type Description <code>LabeledData</code> <p>The labeled ItemList.</p>"},{"location":"utils/data/#cmn_ai.utils.data.LabeledData.process","title":"<code>process(item_list, proc)</code>","text":"<p>Applies processors to an ItemList.</p> <p>Parameters:</p> Name Type Description Default <code>item_list</code> <code>ItemList</code> <p>The ItemList to process.</p> required <code>proc</code> <code>Processor | Iterable[Processor]</code> <p>The processor or list of processors to apply.</p> required <p>Returns:</p> Type Description <code>ItemList</code> <p>The processed ItemList.</p>"},{"location":"utils/data/#cmn_ai.utils.data.LabeledData.x_obj","title":"<code>x_obj(idx)</code>","text":"<p>Returns the input object at index idx after applying all processors in proc_x.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int</code> <p>Index of the input object to retrieve.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The input object at index idx after applying all processors in proc_x.</p>"},{"location":"utils/data/#cmn_ai.utils.data.LabeledData.y_obj","title":"<code>y_obj(idx)</code>","text":"<p>Returns the label object at index idx after applying all processors in proc_y.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int</code> <p>Index of the label object to retrieve.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The label object at index idx after applying all processors in proc_y.</p>"},{"location":"utils/data/#cmn_ai.utils.data.ListContainer","title":"<code>ListContainer</code>","text":"<p>               Bases: <code>UserList</code></p> <p>Extend builtin list by changing the creation of the list from the given items and changing repr to return first 10 items along with total number of items and the class name. This will be the base class where other containers will inherit from.</p>"},{"location":"utils/data/#cmn_ai.utils.data.ListContainer.__init__","title":"<code>__init__(items)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>items</code> <code>Any</code> <p>Items to create list from.</p> required"},{"location":"utils/data/#cmn_ai.utils.data.SplitData","title":"<code>SplitData</code>","text":"<p>Split Item list into train and validation data lists.</p>"},{"location":"utils/data/#cmn_ai.utils.data.SplitData.__init__","title":"<code>__init__(train, valid)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>train</code> <code>ItemList</code> <p>Training items.</p> required <code>valid</code> <code>ItemList</code> <p>Validation items.</p> required"},{"location":"utils/data/#cmn_ai.utils.data.SplitData.split_by_func","title":"<code>split_by_func(item_list, split_func)</code>  <code>classmethod</code>","text":"<p>Split item list by splitter function and returns a SplitData object.</p>"},{"location":"utils/data/#cmn_ai.utils.data.SplitData.to_dls","title":"<code>to_dls(batch_size=32, **kwargs)</code>","text":"<p>Returns a tuple of training and validation DataLoaders using train and valid datasets.</p>"},{"location":"utils/data/#cmn_ai.utils.data.collate_device","title":"<code>collate_device(device)</code>","text":"<p>Collate inputs from batch and copy it to <code>device</code>.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>str | device</code> <p>Device to copy batch to.</p> required <p>Returns:</p> Type Description <code>Callable</code> <p>Wrapper function that returns tuple of collated inputs.</p>"},{"location":"utils/data/#cmn_ai.utils.data.collate_dict","title":"<code>collate_dict(ds)</code>","text":"<p>Collate inputs from HF Dataset dictionary and returns list of inputs after applying pytorch's default collate function.</p> <p>Parameters:</p> Name Type Description Default <code>ds</code> <code>DatasetDict</code> <p>HF Dataset dictionary.</p> required <p>Returns:</p> Type Description <code>Callable</code> <p>Wrapper function that returns tuple of collated inputs.</p>"},{"location":"utils/data/#cmn_ai.utils.data.compose","title":"<code>compose(x, funcs, *args, order='order', **kwargs)</code>","text":"<p>Applies transformations in <code>funcs</code> to the input <code>x</code> in  <code>order</code>.</p>"},{"location":"utils/data/#cmn_ai.utils.data.get_dls","title":"<code>get_dls(train_ds, valid_ds, batch_size, **kwargs)</code>","text":"<p>Returns two dataloaders: 1 for training and 1 for validation. The validation dataloader has twice the batch size and doesn't shuffle data.</p>"},{"location":"utils/data/#cmn_ai.utils.data.get_files","title":"<code>get_files(path, extensions=None, include=None, recurse=False)</code>","text":"<p>Get filenames in <code>path</code> that have extension <code>extensions</code> starting with <code>path</code> and optionally recurse to subdirectories.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path for the root directory to search for files.</p> required <code>extensions</code> <code>str | Iterable[str] | None</code> <p>Suffixes of filenames to look for.</p> <code>None</code> <code>include</code> <code>Iterable[str] | None</code> <p>Top-level Director(y|ies) under <code>path</code> to use to search for files.</p> <code>None</code> <code>recurse</code> <code>bool</code> <p>Whether to search subdirectories recursively.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of filenames that ends with <code>extensions</code> under <code>path</code>.</p>"},{"location":"utils/data/#cmn_ai.utils.data.grandparent_splitter","title":"<code>grandparent_splitter(f_name, valid_name='valid', train_name='train')</code>","text":"<p>Split items based on whether they fall under validation or training directories. This assumes that the directory structure is train/label/items or valid/label/items.</p> <p>Parameters:</p> Name Type Description Default <code>f_name</code> <code>str | Path</code> <p>Item's filename.</p> required <code>valid_name</code> <code>str</code> <p>Name of the directory that holds the validation items.</p> <code>\"valid\"</code> <code>train_name</code> <code>str</code> <p>Name of the directory that holds the training items.</p> <code>\"train\"</code> <p>Returns:</p> Type Description <code>bool | None</code> <p>True if the item is in validation else False (training). If neither, returns None.</p>"},{"location":"utils/data/#cmn_ai.utils.data.label_by_func","title":"<code>label_by_func(splitted_data, label_func, proc_x=None, proc_y=None)</code>","text":"<p>Label splitted data using <code>label_func</code>.</p> <p>Parameters:</p> Name Type Description Default <code>splitted_data</code> <code>SplitData</code> <p>The splitted data to be labeled.</p> required <code>label_func</code> <code>Callable</code> <p>The function to be used for labeling.</p> required <code>proc_x</code> <code>Callable | None</code> <p>The processor to be applied to the input data.</p> <code>None</code> <code>proc_y</code> <code>Callable | None</code> <p>The processor to be applied to the label data.</p> <code>None</code> <p>Returns:</p> Type Description <code>SplitData</code> <p>The labeled splitted data.</p>"},{"location":"utils/data/#cmn_ai.utils.data.parent_labeler","title":"<code>parent_labeler(f_name)</code>","text":"<p>Label a file based on its parent directory.</p> <p>Parameters:</p> Name Type Description Default <code>f_name</code> <code>str | Path</code> <p>Filename to get the parent directory.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Name of the parent directory.</p>"},{"location":"utils/data/#cmn_ai.utils.data.random_splitter","title":"<code>random_splitter(f_name, p_valid=0.2)</code>","text":"<p>Randomly split items with <code>p_valid</code> probability to be in the validation set.</p> <p>Parameters:</p> Name Type Description Default <code>f_name</code> <code>str</code> <p>Item's filename. Not used here, but left for API consistency with other splitters.</p> required <code>p_valid</code> <code>float</code> <p>Probability of the item to be in the validation set.</p> <code>0.2</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the item is in validation else False (training).</p>"},{"location":"utils/data/#cmn_ai.utils.data.split_by_func","title":"<code>split_by_func(items, func)</code>","text":"<p>Split items into train/valid lists using <code>func</code>.</p> <p>Parameters:</p> Name Type Description Default <code>items</code> <code>Iterable</code> <p>Items to be split into train/valid.</p> required <code>func</code> <code>Callable</code> <p>Split function to split items.</p> required <p>Returns:</p> Type Description <code>tuple[list, list]</code> <p>Train and valid item lists.</p>"},{"location":"utils/data/#cmn_ai.utils.data.to_cpu","title":"<code>to_cpu(x)</code>","text":"<p>Copy tensor(s) to CPU. If a tensor is already on the CPU, returns the tensor itself; otherwise, returns a copy of the tensor.</p>"},{"location":"utils/data/#cmn_ai.utils.data.to_device","title":"<code>to_device(x, device=default_device)</code>","text":"<p>Copy tensor(s) to device. If the tensor is already on the device, returns the tensor itself.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor | Iterable[Tensor] | Mapping[str, Tensor]</code> <p>Tensor or collection of tensors to move to device.</p> required <code>device</code> <code>str | device</code> <p>Device to copy the tensor to.</p> <code>'cuda:0` if available else 'cpu'</code> <p>Returns:</p> Name Type Description <code>out</code> <code>Tensor | Iterable[Tensor] | Mapping[str, Tensor]</code> <p>Copied tensor(s) on the <code>device</code>.</p>"},{"location":"utils/processors/","title":"Processors","text":"<p>Processors are meant as transformers for DL datasets that can be used by Dataset object to transform objects before returning a requested item.</p>"},{"location":"utils/processors/#cmn_ai.utils.processors.CategoryProcessor","title":"<code>CategoryProcessor</code>","text":"<p>               Bases: <code>Processor</code></p> <p>Create a vocabulary from training data and use it to numericalize categories/text.</p> <p>Attributes:</p> Name Type Description <code>vocab</code> <code>Sequence[str]</code> <p>Vocabulary used for numericalizing tokens.</p> <code>otoi</code> <code>Dict[str, int]</code> <p>Mapping of tokens to their integer indices.</p>"},{"location":"utils/processors/#cmn_ai.utils.processors.CategoryProcessor.__call__","title":"<code>__call__(items)</code>","text":"<p>Create a vocabulary from items if it doesn't already exist and return their numerical IDs.</p> <p>Parameters:</p> Name Type Description Default <code>items</code> <code>Sequence[str] | str</code> <p>Data to numericalize.</p> required <p>Returns:</p> Type Description <code>list[int] | int</code> <p>Numerical IDs of items.</p>"},{"location":"utils/processors/#cmn_ai.utils.processors.CategoryProcessor.__init__","title":"<code>__init__(vocab=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>vocab</code> <code>Sequence[str] | None</code> <p>Vocabulary to use for numericalizing tokens.</p> <code>None</code>"},{"location":"utils/processors/#cmn_ai.utils.processors.CategoryProcessor.deprocess","title":"<code>deprocess(idxs)</code>","text":"<p>Denumericalize item(s) by converting IDs to actual tokens.</p> <p>Parameters:</p> Name Type Description Default <code>idxs</code> <code>Iterable[int] | int</code> <p>IDs to denumricalize.</p> required <p>Returns:</p> Type Description <code>list[str] | str</code> <p>Tokens that correspond for each ID.</p>"},{"location":"utils/processors/#cmn_ai.utils.processors.CategoryProcessor.process","title":"<code>process(items)</code>","text":"<p>Numericalize item(s).</p> <p>Parameters:</p> Name Type Description Default <code>items</code> <code>Iterable[str] | str</code> <p>Items to numericalize.</p> required <p>Returns:</p> Type Description <code>list[int] | int</code> <p>Numerical IDs of passed items.</p>"},{"location":"utils/processors/#cmn_ai.utils.processors.Processor","title":"<code>Processor</code>","text":"<p>Base class for all processors.</p>"},{"location":"utils/utils/","title":"Utilities","text":"<p>Useful Python utilities.</p>"},{"location":"utils/utils/#cmn_ai.utils.utils.clean_ipython_history","title":"<code>clean_ipython_history()</code>","text":"<p>Clean IPython history. This is very useful when we have output cells with large tensors. Credit: code in this function mainly copied from IPython source.</p>"},{"location":"utils/utils/#cmn_ai.utils.utils.clean_memory","title":"<code>clean_memory()</code>","text":"<p>Clean memory occupied by traceback objects, IPython history, and empty GPU cache.</p>"},{"location":"utils/utils/#cmn_ai.utils.utils.clean_traceback","title":"<code>clean_traceback()</code>","text":"<p>Clean memory used by traceback objects. It comes in handy when traceback has big tensors attached to a traceback while the operation raised <code>Exception</code>. This will lead to the tensor keeps occupying GPU memory and get <code>OOM</code> error even if we try to clean up the GPU memory.</p>"},{"location":"utils/utils/#cmn_ai.utils.utils.listify","title":"<code>listify(obj)</code>","text":"<p>Change type of any object into a list.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>Object to turn into a list.</p> required <p>Returns:</p> Type Description <code>list</code> <p>Returns list of the provided <code>obj</code>.</p>"},{"location":"utils/utils/#cmn_ai.utils.utils.set_printoptions","title":"<code>set_printoptions(precision=2, linewidth=125, sci_mode=False)</code>","text":"<p>Set print options for numpy and pytorch.</p> <p>Parameters:</p> Name Type Description Default <code>precision</code> <code>int</code> <p>Number of digits of precision for floating point output.</p> <code>2</code> <code>linewidth</code> <code>int</code> <p>Number of characters per line before inserting line breaks.</p> <code>125</code> <code>sci_mode</code> <code>bool</code> <p>Whether to enable scientific notation.</p> <code>False</code>"},{"location":"utils/utils/#cmn_ai.utils.utils.set_seed","title":"<code>set_seed(seed=42, deterministic=False)</code>","text":"<p>Set seeds for generating random numbers for pytorch, numpy, and random packages.</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>int</code> <p>Desired seed.</p> <code>42</code> <code>deterministic</code> <code>bool</code> <p>Whether pytorch uses deterministic algorithms.</p> <code>False</code>"},{"location":"utils/utils/#cmn_ai.utils.utils.setify","title":"<code>setify(obj)</code>","text":"<p>Change type of any object into a set.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>Object to turn into a set.</p> required <p>Returns:</p> Type Description <code>set</code> <p>Returns set of the provided <code>obj</code>.</p>"},{"location":"utils/utils/#cmn_ai.utils.utils.tuplify","title":"<code>tuplify(obj)</code>","text":"<p>Change type of any object into a tuple.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>Object to turn into a tuple.</p> required <p>Returns:</p> Type Description <code>tuple</code> <p>Returns tuple of the provided <code>obj</code>.</p>"},{"location":"utils/utils/#cmn_ai.utils.utils.uniqueify","title":"<code>uniqueify(x, sort=False)</code>","text":"<p>Returns a list of unique elements in any iterable, optionally sorted.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Iterable</code> <p>Iterable to get unique elements from.</p> required <code>sort</code> <code>bool</code> <p>Whether to sort the unique elements in the list.</p> <code>False</code> <p>Returns:</p> Type Description <code>list</code> <p>List containing the unique elements, optionally sorted.</p>"},{"location":"vision/core/","title":"Core","text":""},{"location":"vision/core/#cmn_ai.vision.core.VisionLearner","title":"<code>VisionLearner</code>","text":"<p>               Bases: <code>Learner</code></p> <p>Learner that knows how to handle vision's related training/inference.</p>"},{"location":"vision/core/#cmn_ai.vision.core.VisionLearner.show_batch","title":"<code>show_batch(sample_sz, callbacks=None, **kwargs)</code>","text":"<p>Show batch of images of size <code>sample_sz</code>.</p> <p>Parameters:</p> Name Type Description Default <code>sample_sz</code> <code>int</code> <p>Number of input samples to show.</p> <code>1</code> <code>callbacks</code> <code>Iterable[Callback] | None</code> <p>Callbacks to add to the existing callbacks. The added callbacks will be removed  before <code>show_batch</code> returns.</p> <code>None</code>"},{"location":"vision/data/","title":"Data","text":""},{"location":"vision/data/#cmn_ai.vision.data.ImageList","title":"<code>ImageList</code>","text":"<p>               Bases: <code>ItemList</code></p> <p>Build an image list from list of files in the <code>path</code> end with <code>extensions</code>, optionally recursively.</p>"},{"location":"vision/data/#cmn_ai.vision.data.ImageList.from_files","title":"<code>from_files(path, extensions=IMAGE_EXTENSIONS, include=None, recurse=True, tfms=None)</code>  <code>classmethod</code>","text":"<p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path for the root directory to search for files.</p> required <code>extensions</code> <code>str | Iterable[str] | None</code> <p>Suffixes of filenames to look for.</p> <code>IMAGE_EXTENSIONS</code> <code>include</code> <code>Iterable[str] | None</code> <p>Top-level Director(y|ies) under <code>path</code> to use to search for files.</p> <code>None</code> <code>recurse</code> <code>bool</code> <p>Whether to search subdirectories recursively.</p> <code>True</code> <code>tfms</code> <code>Callable | None</code> <p>Transformations to apply items before returning them.</p> <code>None</code>"},{"location":"vision/data/#cmn_ai.vision.data.ImageList.get","title":"<code>get(item)</code>","text":"<p>Open an image using PIL.</p>"}]}